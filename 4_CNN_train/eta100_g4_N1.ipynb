{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmpscratch/tkim12/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import gc\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from model.classifier import Net\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_loc = '/afs/crc.nd.edu/user/t/tkim12/Work/CMB_ML/Data/Nside1024/'\n",
    "\n",
    "# Load background\n",
    "bkg_file = 400\n",
    "CMB_bkg = []\n",
    "for file_num in range(bkg_file):\n",
    "    Xtemp = np.load(file_loc+\"quicklens_backgound/500_events_90Sqr_lensed_Backgroundlmax3500_\"+str(file_num)+\".npy\")\n",
    "    for k in range(Xtemp.shape[0]):\n",
    "        CMB_bkg.append(Xtemp[k])\n",
    "\n",
    "\n",
    "# Load CMB signal only (g = 1)\n",
    "CMB_sig = []\n",
    "for file_num in range(1,201):\n",
    "    Xtemp = np.load(file_loc+\"PHS_signal/500_eta100PHS_g1_Sig_\"+str(file_num)+\".npy\")\n",
    "    for k in range(Xtemp.shape[0]):\n",
    "        CMB_sig.append(Xtemp[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMB_bkg = np.array(CMB_bkg)\n",
    "CMB_sig = np.array(CMB_sig)\n",
    "\n",
    "CMB_bkg_num = CMB_bkg.shape[0]\n",
    "\n",
    "\n",
    "# Prepare pure background and background + signal\n",
    "rescale_val = 3\n",
    "\n",
    "bkgonly = CMB_bkg[0:int(CMB_bkg_num/2)]\n",
    "SpB = CMB_bkg[int(CMB_bkg_num/2):]+ rescale_val *CMB_sig\n",
    "\n",
    "bkg_indicator = np.zeros(int(CMB_bkg_num/2))\n",
    "sig_indicator = np.ones(int(CMB_bkg_num/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plt.imshow(CMB_sig[4])\n",
    "#plt.savefig('sample_img.pdf')\n",
    "sig_indicator[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 90\n",
      "Training sample : 160000 , Validation sample : 40000\n"
     ]
    }
   ],
   "source": [
    "X_data = np.concatenate((bkgonly,      SpB          ))\n",
    "Y_data = np.concatenate((bkg_indicator,sig_indicator))\n",
    "\n",
    "wid, hei = X_data.shape[1], X_data.shape[2]\n",
    "\n",
    "X_data, Y_data = shuffle(X_data, Y_data, random_state=23)\n",
    "\n",
    "print(wid, hei)\n",
    "#print(Y_data)\n",
    "\n",
    "# Data Splitting\n",
    "ts1 = 0.2\n",
    "rs1 = 24\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size = ts1, random_state = rs1)\n",
    "\n",
    "X_data = []\n",
    "Y_data = []\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, wid, hei).astype('float64')\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, wid, hei).astype('float64')\n",
    "X_test = torch.from_numpy(X_test)\n",
    "\n",
    "Y_train = Y_train.reshape(Y_train.shape[0], 1).astype('float64')\n",
    "Y_train = torch.from_numpy(Y_train)\n",
    "Y_test = Y_test.reshape(Y_test.shape[0], 1).astype('float64')\n",
    "Y_test = torch.from_numpy(Y_test)\n",
    "\n",
    "print(\"Training sample : \"+str(X_train.shape[0])+\" , Validation sample : \"+str(X_test.shape[0]))\n",
    "\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "train_data = TensorDataset(X_train, Y_train)\n",
    "test_data = TensorDataset(X_test, Y_test)\n",
    "\n",
    "trainloader = DataLoader(dataset=train_data, batch_size=128, shuffle=True)\n",
    "testloader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(16, 16), stride=(2, 2), padding=(7, 7))\n",
      "  (conv2): Conv2d(8, 8, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv2d(8, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (avepool): AvgPool2d(kernel_size=(2, 2), stride=(1, 1), padding=0)\n",
      "  (fc1): Linear(in_features=128, out_features=200, bias=True)\n",
      "  (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (fin): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trained_class = './result/eta100_gpu_classification_g4train.pt'\n",
    "class_model = Net()\n",
    "class_model.load_state_dict(torch.load(trained_class, map_location=torch.device('cpu')))\n",
    "class_model.eval()\n",
    "model = class_model.double()\n",
    "\n",
    "#model = Net()\n",
    "#model = model.double()\n",
    "print(model)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "#from tqdm import tqdm\n",
    "# https://medium.com/analytics-vidhya/simple-neural-network-with-bceloss-for-binary-classification-for-a-custom-dataset-8d5c69ffffee\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs=20, lr=0.0001):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train() # train mode (affects batchnorm layers:\n",
    "                      # in the subsequent forward passes they'll\n",
    "                      # exhibit 'train' behaviour, i.e. they'll\n",
    "                      # normalize activations over batches)\n",
    "        for i, (X, y) in enumerate(tqdm(trainloader)):\n",
    "        #for i, (X, y) in enumerate(trainloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            #print(X.is_cuda, y.is_cuda)\n",
    "\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_loss.append(np.mean(loss.item()))\n",
    "            train_accuracy.append((pred.round() == y).to(torch.float32).mean().item())\n",
    "\n",
    "        model.eval() # test mode (affects batchnorm layers:\n",
    "                     # in the subsequent forward passes they'll\n",
    "                     # exhibit 'test' behaviour, i.e. they'll\n",
    "                     # use the accumulated running statistics\n",
    "                     # to normalize activations)\n",
    "        epoch_losses = []\n",
    "        epoch_accuracies = []\n",
    "        with torch.no_grad(): # avoid calculating gradients during evaluation\n",
    "            for X, y in testloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                pred = model(X)\n",
    "                pred_round = pred.round()\n",
    "\n",
    "                epoch_losses.append(loss_fn(pred, y).item())\n",
    "                _, pred = torch.max(pred.data, 1) # pred = index of maximal output along axis=1\n",
    "                epoch_accuracies.append(\n",
    "                    (pred_round == y).to(torch.float32).mean().item()\n",
    "                )\n",
    "        test_loss.append(np.mean(epoch_losses))\n",
    "        print(\"\\n Epoch = \",epoch)\n",
    "        print(\"\\n Training loss = \", np.mean(train_loss))\n",
    "        print(\"\\n Validation loss = \", np.mean(epoch_losses))\n",
    "        #print(\"\\n Training acc = \", train_accuracy)\n",
    "        print(\"\\n Validation acc = \", np.mean(epoch_accuracies))\n",
    "        test_accuracy.append(np.mean(epoch_accuracies))\n",
    "\n",
    "    return dict(\n",
    "        train_loss=train_loss,\n",
    "        test_loss=test_loss,\n",
    "        train_accuracy=train_accuracy,\n",
    "        test_accuracy=test_accuracy\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [01:53<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch =  0\n",
      "\n",
      " Training loss =  0.031298653628113376\n",
      "\n",
      " Validation loss =  0.05921913820146898\n",
      "\n",
      " Validation acc =  0.98135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [01:53<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch =  1\n",
      "\n",
      " Training loss =  0.03205292987732784\n",
      "\n",
      " Validation loss =  0.0573627943223681\n",
      "\n",
      " Validation acc =  0.9824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [01:53<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch =  2\n",
      "\n",
      " Training loss =  0.031836187359922344\n",
      "\n",
      " Validation loss =  0.05507296922914572\n",
      "\n",
      " Validation acc =  0.9831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [01:53<00:00, 11.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch =  3\n",
      "\n",
      " Training loss =  0.03148812342097017\n",
      "\n",
      " Validation loss =  0.05518341977448126\n",
      "\n",
      " Validation acc =  0.9826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [01:53<00:00, 10.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch =  4\n",
      "\n",
      " Training loss =  0.030970626216211328\n",
      "\n",
      " Validation loss =  0.05576358625694778\n",
      "\n",
      " Validation acc =  0.982375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [01:53<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch =  5\n",
      "\n",
      " Training loss =  0.030720912940419058\n",
      "\n",
      " Validation loss =  0.06059241048588421\n",
      "\n",
      " Validation acc =  0.98155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1075/1250 [01:37<00:15, 11.01it/s]"
     ]
    }
   ],
   "source": [
    "result = train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the validation images: 96 %\n"
     ]
    }
   ],
   "source": [
    "#dataiter = iter(testloader)\n",
    "#images, labels = dataiter.next()\n",
    "\n",
    "#outputs = model(images)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images).round()\n",
    "        #print(\"Expected : \", labels, \"Predicted : \", outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (outputs == labels).sum().item()\n",
    "        #if (outputs == labels).sum().item() ==0:\n",
    "        #    print(\"Expected : \", labels, \"Predicted : \", outputs)\n",
    "\n",
    "print('Accuracy of the network on the validation images: %d %%' % (100. * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path = \"./result/eta100_gpu_classification_g\"+str(rescale_val)+\"train.pt\"\n",
    "torch.save(model.state_dict(), Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
